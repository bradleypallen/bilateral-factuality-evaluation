{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_SIZE = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unilateral_performance(df):\n",
    "    model_evals = df.groupby('model_name')['evaluation'].value_counts().unstack(fill_value=0)\n",
    "    model_evals[\"correct (t)\"] = model_evals[\"t\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"not attempted (n)\"] = model_evals[\"n\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"incorrect (f)\"] = model_evals[\"f\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"correct given attempted\"] = model_evals[\"t\"] / (model_evals[\"t\"] + model_evals[\"f\"])\n",
    "    model_evals[\"F score\"] = (2.*model_evals[\"t\"]) / ((2.*model_evals[\"t\"]) + (2.*model_evals[\"f\"]) + model_evals[\"n\"])\n",
    "    model_evals = model_evals.sort_values(\"correct given attempted\", ascending=False)\n",
    "    return model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_performance(df):\n",
    "    model_evals = df.groupby('model_name')['evaluation'].value_counts().unstack(fill_value=0)\n",
    "    model_evals[\"correct (t)\"] = model_evals[\"t\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"inconsistent (b)\"] = model_evals[\"b\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"unknown (n)\"] = model_evals[\"n\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"incorrect (f)\"] = model_evals[\"f\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"not attempted (b+n)\"] = (model_evals[\"b\"] + model_evals[\"n\"]) / BENCHMARK_SIZE\n",
    "    model_evals[\"correct given attempted\"] = model_evals[\"t\"] / (model_evals[\"t\"] + model_evals[\"f\"])\n",
    "    model_evals[\"F score\"] = (2.*model_evals[\"t\"]) / ((2.*model_evals[\"t\"]) + (2.*model_evals[\"f\"]) + (model_evals[\"b\"] + model_evals[\"n\"]))\n",
    "    model_evals = model_evals.sort_values(\"correct given attempted\", ascending=False)\n",
    "    return model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluation</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>correct (t)</th>\n",
       "      <th>not attempted (n)</th>\n",
       "      <th>incorrect (f)</th>\n",
       "      <th>correct given attempted</th>\n",
       "      <th>F score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>845</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-11-20</th>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>377</td>\n",
       "      <td>12</td>\n",
       "      <td>611</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>524</td>\n",
       "      <td>2</td>\n",
       "      <td>474</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-haiku-20241022</th>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluation                              f   n    t  correct (t)  \\\n",
       "model_name                                                        \n",
       "mistralai/Mistral-7B-Instruct-v0.3    155   0  845        0.845   \n",
       "gpt-4o-2024-11-20                     285   0  715        0.715   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1  377  12  611        0.611   \n",
       "gpt-4o-mini                           524   2  474        0.474   \n",
       "claude-3-5-haiku-20241022             879   1  120        0.120   \n",
       "\n",
       "evaluation                            not attempted (n)  incorrect (f)  \\\n",
       "model_name                                                               \n",
       "mistralai/Mistral-7B-Instruct-v0.3                0.000          0.155   \n",
       "gpt-4o-2024-11-20                                 0.000          0.285   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1              0.012          0.377   \n",
       "gpt-4o-mini                                       0.002          0.524   \n",
       "claude-3-5-haiku-20241022                         0.001          0.879   \n",
       "\n",
       "evaluation                            correct given attempted  F score  \n",
       "model_name                                                              \n",
       "mistralai/Mistral-7B-Instruct-v0.3                      0.845    0.845  \n",
       "gpt-4o-2024-11-20                                       0.715    0.715  \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1                    0.618    0.615  \n",
       "gpt-4o-mini                                             0.475    0.474  \n",
       "claude-3-5-haiku-20241022                               0.120    0.120  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unilateral_results = []\n",
    "for file in glob.glob(\"experiments/unilateral/*.json\"):\n",
    "   unilateral_results += json.load(open(file, \"r\"))\n",
    "df_unilateral = pd.DataFrame(unilateral_results)\n",
    "unilateral_performance(df_unilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluation</th>\n",
       "      <th>b</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>correct (t)</th>\n",
       "      <th>inconsistent (b)</th>\n",
       "      <th>unknown (n)</th>\n",
       "      <th>incorrect (f)</th>\n",
       "      <th>not attempted (b+n)</th>\n",
       "      <th>correct given attempted</th>\n",
       "      <th>F score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>129</td>\n",
       "      <td>80</td>\n",
       "      <td>244</td>\n",
       "      <td>547</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>203</td>\n",
       "      <td>88</td>\n",
       "      <td>119</td>\n",
       "      <td>590</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-11-20</th>\n",
       "      <td>125</td>\n",
       "      <td>141</td>\n",
       "      <td>399</td>\n",
       "      <td>335</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>212</td>\n",
       "      <td>149</td>\n",
       "      <td>299</td>\n",
       "      <td>340</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-haiku-20241022</th>\n",
       "      <td>82</td>\n",
       "      <td>125</td>\n",
       "      <td>559</td>\n",
       "      <td>234</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluation                              b    f    n    t  correct (t)  \\\n",
       "model_name                                                              \n",
       "gpt-4o-mini                           129   80  244  547        0.547   \n",
       "mistralai/Mistral-7B-Instruct-v0.3    203   88  119  590        0.590   \n",
       "gpt-4o-2024-11-20                     125  141  399  335        0.335   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1  212  149  299  340        0.340   \n",
       "claude-3-5-haiku-20241022              82  125  559  234        0.234   \n",
       "\n",
       "evaluation                            inconsistent (b)  unknown (n)  \\\n",
       "model_name                                                            \n",
       "gpt-4o-mini                                      0.129        0.244   \n",
       "mistralai/Mistral-7B-Instruct-v0.3               0.203        0.119   \n",
       "gpt-4o-2024-11-20                                0.125        0.399   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1             0.212        0.299   \n",
       "claude-3-5-haiku-20241022                        0.082        0.559   \n",
       "\n",
       "evaluation                            incorrect (f)  not attempted (b+n)  \\\n",
       "model_name                                                                 \n",
       "gpt-4o-mini                                   0.080                0.373   \n",
       "mistralai/Mistral-7B-Instruct-v0.3            0.088                0.322   \n",
       "gpt-4o-2024-11-20                             0.141                0.524   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1          0.149                0.511   \n",
       "claude-3-5-haiku-20241022                     0.125                0.641   \n",
       "\n",
       "evaluation                            correct given attempted  F score  \n",
       "model_name                                                              \n",
       "gpt-4o-mini                                             0.872    0.672  \n",
       "mistralai/Mistral-7B-Instruct-v0.3                      0.870    0.703  \n",
       "gpt-4o-2024-11-20                                       0.704    0.454  \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1                    0.695    0.457  \n",
       "claude-3-5-haiku-20241022                               0.652    0.344  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilateral_results = []\n",
    "for file in glob.glob(\"experiments/bilateral/*.json\"):\n",
    "   bilateral_results += json.load(open(file, \"r\"))\n",
    "df_bilateral = pd.DataFrame(bilateral_results)\n",
    "bilateral_performance(df_bilateral)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
