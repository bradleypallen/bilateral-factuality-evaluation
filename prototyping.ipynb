{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from datetime import datetime, timezone\n",
    "from tqdm import tqdm\n",
    "from bilateral_factuality_evaluator import BilateralFactualityEvaluator\n",
    "import pandas, re, json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\n",
    "    \"https://openaipublic.blob.core.windows.net/simple-evals/simple_qa_test_set.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_QA_DATASET = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_PROMPT = \"\"\"Here is a factual question and a potential answer. \n",
    "Your task is to assess whether the answer is true. \n",
    "Please first explain your reasoning step by step, \n",
    "then conclude with either \"TRUE\" if you have determined that the answer is true, \n",
    "otherwise \"CANNOT DETERMINE TRUE\", \n",
    "and only those conclusions, \n",
    "at the very end of your reasoning.\n",
    "\n",
    "Reasoning steps: \n",
    "1. First verify the essential information is present \n",
    "2. Check for any supporting facts \n",
    "3. Consider question context for implied terms \n",
    "4. Note if any missing information is essential vs optional \n",
    "\n",
    "Question: {problem}\n",
    "Answer: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FALSIFICATION_PROMPT = \"\"\"Here is a factual question and a potential answer. \n",
    "Your task is to assess whether the answer is false. \n",
    "Please first explain your reasoning step by step, \n",
    "then conclude with either \"FALSE\" if you have determined that the answer is false, \n",
    "otherwise \"CANNOT DETERMINE FALSE\", \n",
    "and only those conclusions, \n",
    "at the very end of your reasoning.\n",
    "\n",
    "Reasoning steps: \n",
    "1. First verify the essential information is present \n",
    "2. Check for any contradictory facts\n",
    "3. Consider question context for implied terms \n",
    "4. Note if any missing information is essential vs optional \n",
    "\n",
    "Question: {problem}\n",
    "Answer: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PARSER = RegexParser(\n",
    "    regex=r\"(TRUE|FALSE|CANNOT DETERMINE FALSE|CANNOT DETERMINE TRUE)\",\n",
    "    output_keys=[\"metadata\", \"problem\", \"answer\", \"text\"],\n",
    "    default_output_key=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [ \n",
    "    { \"model_name\": \"gpt-4o-mini\", \"batch_size\": 100 },\n",
    "    # { \"model_name\": \"gpt-4o-2024-05-13\", \"batch_size\": 100 },\n",
    "    # { \"model_name\": \"gpt-4-0125-preview\", \"batch_size\": 50 },\n",
    "    # { \"model_name\": \"mistralai/Mistral-7B-Instruct-v0.3\", \"batch_size\": 50 },\n",
    "    # { \"model_name\": \"claude-3-5-sonnet-20240620\", \"batch_size\": 1 },\n",
    "    { \"model_name\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\", \"batch_size\": 50 },\n",
    "    # { \"model_name\": \"claude-3-opus-20240229\", \"batch_size\": 1 },\n",
    "    # { \"model_name\": \"meta-llama/Meta-Llama-3-70B-Instruct\", \"batch_size\": 50 },\n",
    "    # { \"model_name\": \"claude-3-haiku-20240307\", \"batch_size\": 1 },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_string(text):\n",
    "    pattern = r'\\b(TRUE|CANNOT DETERMINE TRUE|FALSE|CANNOT DETERMINE FALSE)\\b'\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v4(verification_result, falsification_result):\n",
    "    if verification_result == 'TRUE':\n",
    "        if falsification_result == 'FALSE':\n",
    "            return 'b'\n",
    "        elif falsification_result == 'CANNOT DETERMINE FALSE':\n",
    "            return 't'\n",
    "        else:\n",
    "            return None\n",
    "    elif verification_result == 'CANNOT DETERMINE TRUE':\n",
    "        if falsification_result == 'FALSE':\n",
    "            return 'f'\n",
    "        elif falsification_result == 'CANNOT DETERMINE FALSE':\n",
    "            return 'n'\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(model, temperature=0.1):\n",
    "    if model in [ \"gpt-3.5-turbo\", \"gpt-4-1106-preview\", \"gpt-4-0125-preview\", \"gpt-4o-2024-05-13\", \"gpt-4o-mini\" ]:\n",
    "        return ChatOpenAI(model_name=model, temperature=temperature)\n",
    "    elif model in [ \"claude-3-opus-20240229\", \"claude-3-5-sonnet-20240620\", \"claude-3-haiku-20240307\" ]:\n",
    "        return ChatAnthropic(\n",
    "            temperature=temperature, \n",
    "            anthropic_api_key=os.environ[\"ANTHROPIC_API_KEY\"], \n",
    "            model_name=model\n",
    "        )\n",
    "    elif model in [ \"gemini-1.0-pro\" ]:\n",
    "        return ChatGooglePalm(\n",
    "            temperature=temperature, \n",
    "            google_api_key=os.environ[\"GOOGLE_API_KEY\"], \n",
    "            model=model\n",
    "        )\n",
    "    elif model in [\n",
    "        \"meta-llama/Llama-2-70b-chat-hf\", \n",
    "        \"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "        \"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "        \"google/gemma-2-9b-it\",\n",
    "        \"google/gemma-7b-it\", \n",
    "        \"google/gemma-2b-it\",\n",
    "        \"meta-llama/Meta-Llama-3-70B-Instruct\", \n",
    "        \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "        ]:\n",
    "        return HuggingFaceEndpoint(\n",
    "            repo_id=model, \n",
    "            temperature=temperature, \n",
    "            timeout=300,\n",
    "            huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(f'Model {model} not supported')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini                         : EXISTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mistralai/Mixtral-8x7B-Instruct-v0.1: 100%|██████████| 87/87 [9:34:06<00:00, 395.94s/it]  \n"
     ]
    }
   ],
   "source": [
    "for model in MODELS:\n",
    "    filename = f'experiments/{model[\"model_name\"].split(\"/\")[-1]}-simpleqa.json'\n",
    "    if os.path.isfile(filename):\n",
    "        print(f'{model[\"model_name\"]:36}: EXISTS')\n",
    "    else:\n",
    "        results = []\n",
    "        batches = [ SIMPLE_QA_DATASET[i:i+model[\"batch_size\"]] for i in range(0, len(SIMPLE_QA_DATASET), model[\"batch_size\"]) ] \n",
    "        llm = get_llm(model[\"model_name\"])\n",
    "        verify_prompt = PromptTemplate(input_variables=[\"problem\", \"answer\"], template=VERIFICATION_PROMPT)\n",
    "        falsify_prompt = PromptTemplate(input_variables=[\"problem\", \"answer\"], template=FALSIFICATION_PROMPT)\n",
    "        verify_chain = verify_prompt | llm\n",
    "        falsify_chain = falsify_prompt | llm\n",
    "        for batch in tqdm(batches, desc=f'{model[\"model_name\"]:36}', total=len(batches)):\n",
    "            falsifications = falsify_chain.batch(batch)\n",
    "            verifications = verify_chain.batch(batch)\n",
    "            for i in range(len(verifications)):\n",
    "                results.append({\n",
    "                    \"metadata\": batch[i][\"metadata\"],\n",
    "                    \"problem\": batch[i][\"problem\"],\n",
    "                    \"answer\": batch[i][\"answer\"],\n",
    "                    \"model_name\": model[\"model_name\"],\n",
    "                    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "                    # \"total_tokens\": verifications[i].response_metadata[\"token_usage\"][\"total_tokens\"] + falsifications[i].response_metadata[\"token_usage\"][\"total_tokens\"],\n",
    "                    # \"verification\": verifications[i].content,\n",
    "                    # \"falsification\": falsifications[i].content,\n",
    "                    \"verification\": verifications[i],\n",
    "                    \"falsification\": falsifications[i],\n",
    "                    # \"evaluation\": v4(get_matched_string(verifications[i].content), get_matched_string(falsifications[i].content))\n",
    "                    \"evaluation\": v4(get_matched_string(verifications[i]), get_matched_string(falsifications[i]))\n",
    "                })\n",
    "            json.dump(results, open(filename, \"w+\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
