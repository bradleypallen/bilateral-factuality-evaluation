{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_SIZE = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unilateral_performance(df):\n",
    "    model_evals = df.groupby('model_name')['evaluation'].value_counts().unstack(fill_value=0)\n",
    "    model_evals[\"correct (t)\"] = model_evals[\"t\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"not attempted (n)\"] = model_evals[\"n\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"incorrect (f)\"] = model_evals[\"f\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"correct given attempted\"] = model_evals[\"t\"] / (model_evals[\"t\"] + model_evals[\"f\"])\n",
    "    model_evals[\"F score\"] = (2.*model_evals[\"t\"]) / ((2.*model_evals[\"t\"]) + (2.*model_evals[\"f\"]) + model_evals[\"n\"])\n",
    "    return model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_performance(df):\n",
    "    model_evals = df.groupby('model_name')['evaluation'].value_counts().unstack(fill_value=0)\n",
    "    model_evals[\"correct (t)\"] = model_evals[\"t\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"inconsistent (b)\"] = model_evals[\"b\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"unknown (n)\"] = model_evals[\"n\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"incorrect (f)\"] = model_evals[\"f\"] / BENCHMARK_SIZE\n",
    "    model_evals[\"not attempted (b+n)\"] = (model_evals[\"b\"] + model_evals[\"n\"]) / BENCHMARK_SIZE\n",
    "    model_evals[\"correct given attempted\"] = model_evals[\"t\"] / (model_evals[\"t\"] + model_evals[\"f\"])\n",
    "    model_evals[\"F score\"] = (2.*model_evals[\"t\"]) / ((2.*model_evals[\"t\"]) + (2.*model_evals[\"f\"]) + (model_evals[\"b\"] + model_evals[\"n\"]))\n",
    "    return model_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluation</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>correct (t)</th>\n",
       "      <th>not attempted (n)</th>\n",
       "      <th>incorrect (f)</th>\n",
       "      <th>correct given attempted</th>\n",
       "      <th>F score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-11-20</th>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>524</td>\n",
       "      <td>2</td>\n",
       "      <td>474</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>845</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>377</td>\n",
       "      <td>12</td>\n",
       "      <td>611</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluation                              f   n    t  correct (t)  \\\n",
       "model_name                                                        \n",
       "gpt-4o-2024-11-20                     285   0  715        0.715   \n",
       "gpt-4o-mini                           524   2  474        0.474   \n",
       "mistralai/Mistral-7B-Instruct-v0.3    155   0  845        0.845   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1  377  12  611        0.611   \n",
       "\n",
       "evaluation                            not attempted (n)  incorrect (f)  \\\n",
       "model_name                                                               \n",
       "gpt-4o-2024-11-20                                 0.000          0.285   \n",
       "gpt-4o-mini                                       0.002          0.524   \n",
       "mistralai/Mistral-7B-Instruct-v0.3                0.000          0.155   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1              0.012          0.377   \n",
       "\n",
       "evaluation                            correct given attempted  F score  \n",
       "model_name                                                              \n",
       "gpt-4o-2024-11-20                                       0.715    0.715  \n",
       "gpt-4o-mini                                             0.475    0.474  \n",
       "mistralai/Mistral-7B-Instruct-v0.3                      0.845    0.845  \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1                    0.618    0.615  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unilateral_results = []\n",
    "for file in glob.glob(\"experiments/unilateral/*.json\"):\n",
    "   unilateral_results += json.load(open(file, \"r\"))\n",
    "df_unilateral = pd.DataFrame(unilateral_results)\n",
    "unilateral_performance(df_unilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluation</th>\n",
       "      <th>b</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>t</th>\n",
       "      <th>correct (t)</th>\n",
       "      <th>inconsistent (b)</th>\n",
       "      <th>unknown (n)</th>\n",
       "      <th>incorrect (f)</th>\n",
       "      <th>not attempted (b+n)</th>\n",
       "      <th>correct given attempted</th>\n",
       "      <th>F score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-11-20</th>\n",
       "      <td>128</td>\n",
       "      <td>213</td>\n",
       "      <td>409</td>\n",
       "      <td>250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>357</td>\n",
       "      <td>295</td>\n",
       "      <td>273</td>\n",
       "      <td>75</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-7B-Instruct-v0.3</th>\n",
       "      <td>664</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>219</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <td>188</td>\n",
       "      <td>59</td>\n",
       "      <td>189</td>\n",
       "      <td>564</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluation                              b    f    n    t  correct (t)  \\\n",
       "model_name                                                              \n",
       "gpt-4o-2024-11-20                     128  213  409  250        0.250   \n",
       "gpt-4o-mini                           357  295  273   75        0.075   \n",
       "mistralai/Mistral-7B-Instruct-v0.3    664   95   22  219        0.219   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1  188   59  189  564        0.564   \n",
       "\n",
       "evaluation                            inconsistent (b)  unknown (n)  \\\n",
       "model_name                                                            \n",
       "gpt-4o-2024-11-20                                0.128        0.409   \n",
       "gpt-4o-mini                                      0.357        0.273   \n",
       "mistralai/Mistral-7B-Instruct-v0.3               0.664        0.022   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1             0.188        0.189   \n",
       "\n",
       "evaluation                            incorrect (f)  not attempted (b+n)  \\\n",
       "model_name                                                                 \n",
       "gpt-4o-2024-11-20                             0.213                0.537   \n",
       "gpt-4o-mini                                   0.295                0.630   \n",
       "mistralai/Mistral-7B-Instruct-v0.3            0.095                0.686   \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1          0.059                0.377   \n",
       "\n",
       "evaluation                            correct given attempted  F score  \n",
       "model_name                                                              \n",
       "gpt-4o-2024-11-20                                       0.540    0.342  \n",
       "gpt-4o-mini                                             0.203    0.109  \n",
       "mistralai/Mistral-7B-Instruct-v0.3                      0.697    0.333  \n",
       "mistralai/Mixtral-8x7B-Instruct-v0.1                    0.905    0.695  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilateral_results = []\n",
    "for file in glob.glob(\"experiments/bilateral/*.json\"):\n",
    "   bilateral_results += json.load(open(file, \"r\"))\n",
    "df_bilateral = pd.DataFrame(bilateral_results)\n",
    "bilateral_performance(df_bilateral)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
